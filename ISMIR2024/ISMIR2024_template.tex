% SIMILAR ISMIR PAPERS
% https://archives.ismir.net/ismir2023/paper/000045.pdf (I'm modeling my paper mostly from this)
% https://tomcollinsresearch.net/pdf/ismirReviewExamples.pdf (these are examples of ISMIR papers that aren't necessarily similar but have been heavily commented on by actual ISMIR reciewers)

% -----------------------------------------------
% Template for ISMIR Papers
% 2023 version, based on previous ISMIR templates

% Requirements :
% * 6+n page length maximum
% * 10MB maximum file size
% * Copyright note must appear in the bottom left corner of first page
% * Clearer statement about citing own work in anonymized submission
% (see conference website for additional details)
% -----------------------------------------------

\documentclass{article}
\usepackage[T1]{fontenc} % add special characters (e.g., umlaute)
\usepackage[utf8]{inputenc} % set utf-8 as default input encoding
\usepackage{ismir,amsmath,cite,url}
\usepackage{graphicx}
\usepackage{color}
\usepackage{listings}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}

% Configure listings
\lstset{
    basicstyle=\footnotesize\ttfamily, % Set the font size and type
    breaklines=true,                    % Allow breaking lines
    tabsize=2,                          % Set tab size
    columns=flexible,                   % For better handling within columns
}

\usepackage{lineno}
%\linenumbers

% Title. Please use IEEE-compliant title case when specifying the title here,
% as it has implications for the copyright notice
% ------
\title{Synthesizing Composite Hierarchical Structure from Music Datasets}

% Note: Please do NOT use \thanks or a \footnote in any of the author markup

% Single address
% To use with only one author or several with the same address
% ---------------
\oneauthor
	{Ilana Shapiro}
	{UC San Diego \\ {\tt ilshapiro@ucsd.edu}}
 %{Names should be omitted for double-blind reviewing}
 %{Affiliations should be omitted for double-blind reviewing}

% Two addresses
% --------------
%\twoauthors
%  {First author} {School \\ Department}
%  {Second author} {Company \\ Address}

% Three addresses
% --------------\input{ISMIR2021_paper.tex}

%\threeauthors
%  {Ilana Shapiro} {Affiliation1 \\ {\tt author1@ismir.edu}}
%  {Second Author} {\bf Retain these fake authors in\\\bf submission to preserve the formatting}
%  {Third Author} {Affiliation3 \\ {\tt author3@ismir.edu}}

% Four or more addresses
% OR alternative format for large number of co-authors
% ------------
%\multauthor
%{First author$^1$ \hspace{1cm} Second author$^1$ \hspace{1cm} Third author$^2$} { \bfseries{Fourth author$^3$ \hspace{1cm} Fifth author$^2$ \hspace{1cm} Sixth author$^1$}\\
%  $^1$ Department of Computer Science, University , Country\\
%$^2$ International Laboratories, City, Country\\
%$^3$  Company, Address\\
%{\tt\small CorrespondenceAuthor@ismir.edu, PossibleOtherAuthor@ismir.edu}
%}

% For the author list in the Creative Common license, please enter author names. 
% Please abbreviate the first names of authors and add 'and' between the second to last and last authors.
\def\authorname{Ilana Shapiro}

% Optional: To use hyperref, uncomment the following.
%\usepackage[bookmarks=false,pdfauthor={\authorname},pdfsubject={\papersubject},hidelinks]{hyperref}
% Mind the bookmarks=false option; bookmarks are incompatible with ismir.sty.

\sloppy % please retain sloppy command for improved formatting

\begin{document}

%
\maketitle
%

%We adopt a ``(6+n)-page policy'' for ISMIR \conferenceyear. That is, each paper may have a maximum of six pages of technical content (including figures and tables) \textcolor{red}{with additional optional pages that contain only references and acknowledgments. Note that acknowledgments should not be included in the anonymized submission.}
%Paper should be submitted as PDFs and the \textcolor{red}{file size is limited to 10MB}. Please compress images and figures as necessary before submitting.

\begin{abstract}
Music is an innately hierarchical system, comprising multiple semantic levels informed by music theory. Such levels include formal structure segmentation, disjoint motif repetition, and harmonic and melodic contour. Historically, researchers in the music information retrieval community have focused on developing analyses for single levels in this hierarchy. However, existing research has addressed neither (1) how to combine arbitrarily many levels of structure analyses into a single unified model and (2) how to extract a representative such structure from a corpus of music, rather than just a single piece. In this work, we propose a novel data structure called the \textit{semantic temporal graph} that captures the semantic (i.e. hierarchical music theoretic) relationships between levels of the hierarchy, as well as the temporal relationships between adjacent-level analyses. Furthermore, given a corpus of such graphs derived from individual pieces, we introduce a method rooted in stochastic optimization to derive a representative $centroid$ graph encoding the music dataset's overall structure. We provide a qualitative evaluation of the semantic temporal graph [where we.....], as well as a quantitative evaluation of the centroid graph [where we...].
% and evaluate??
\end{abstract}


%
\section{Introduction}\label{sec:intro}
Music is both composed and comprehended with a hierarchical structure. Melodies comprising individual notes form the bottom of the hierarchy, followed by harmonic contour, rhythmic patterns, disjoint motifs, and finally large scale sections. Together, this composite hierarchy defines the overall structure of a piece \cite{msaf}.

Automatic identification of musical structure, also known as \textit{music structure analysis} (MSA), is a major interest to both musicologists and the MIR community. Research thus far has focused on the automatic contiguous segmentation (both flat and hierarchical) of musical form \cite{msaf, checkerboard, sf, vmo_segmentation, cnmf, 2dfmc, eval_hier, olda, scluster, musicaiz, repetition_grammars_ismir2023, buisson_2022, cmu_dannenberg_2020}, involving a boundary detection step followed by a segment labeling step. Motif detection \cite{Hsiao_2023_motifs, vmo_motifs, features_motifs}, which looks for disjoint repeating musical patterns, has also been investigated. More recently, researchers have studied harmonic \cite{chen_2019_harmony}, functional harmonic \cite{chen_2018_harmony}, and melodic \cite{salamon_2013_melody, kosta_22_melody, midibert} contour extraction. The techniques used are diverse, ranging from matrix factorization to deep learning. These tasks have all been proposed in annual competitions of the Music Information Retrieval eXchange (MIREX) \cite{MIREX_2017_form, MIREX_2017_motif, MIREX_2010_harmony, MIREX_2021_melody}, which provides a standard output format. 

To our knowledge, all existing MSA research addresses a single aspect of the compositional hierarchy, such as motif extraction, or melodic contour. There is currently no notion of how reconcile differing levels of the hierarchy into a single, unified model of  structure, even though their amalgamation is central to a piece's compositional architecture and cohesive integrity. Indeed, Dai et al. have shown empirically that there are significant interactions between different structural levels \cite{cmu_dannenberg_2020}. In identifying the components necessary for integrating the levels, we find there are two central challenges: how to convey each level's semantic, music theoretic level in the hierarchy, and how to encapsulate the temporal relationships between the results of the structural analyses at adjacent hierarchical levels. 

Furthermore, prior MSA research has only addressed the problem of identifying structure in a single piece, and there is presently no methodology for describing the overall structure of a musical corpus, even across existing single-level analyses. The one exception is Oriol Nieto's proposed technique for merging multiple segment boundary annotations \cite{msaf}, but this is intended to be used with multiple boundary detection algorithms over a single piece to alleviate the problem of subjectivity, and does not address the problem of reconciling differing labels or levels.  

\subsection{Contributions}\label{subsec:contributions}

To address the first gap, in Section \ref{sec:representation} we introduce the \textit{semantic temporal graph} (STG), a $k$-partite directed acyclic graph (DAG). In this novel data structure, the semantic, music theoretic levels of the compositional hierarchy are represented as levels in the $k$-partite structure, nodes represent structure labels that are the result of the relevant analysis, and edges between nodes of adjacent levels convey the temporal relationships between them. Each node has an associated time interval determined by the relevant MSA algorithm. A node must have one or two parents at the level above it: one if its associated time interval is a total subset of its parents, and two if its time interval begins in one parent and ends in the other. In order to easily parse the results of MSA algorithms into this data structure, the standard MIREX format is consulted.

Importantly, the STG is incredibly flexible, and supports the representation of arbitrarily many layers and layer types. Furthermore, the STG is totally decoupled from any specific MSA algorithm or input format, meaning that the chosen MSA algorithm for any level can be easily swapped out, as long as its output adheres to the standard MIREX format. This is crucial as single-level MSA algorithms are constantly improving, and the STG must be adaptable enough to accommodate this.

Finally, to address the second gap, in Section \ref{sec:synthesis} we examine the problem of finding a \textit{centroid}, or most representative, graph given a corpus of STGs derived from individual pieces. We use the label-aware graph edit distance as the cost between two STGs. Given a set of STGs $G$, we seek to construct the STG $g*$ that minimizes this cost from $g*$ to every graph in $G$. This is a constraint satisfaction problem, but is NP-hard and intractable at this size. Thus, we must rely on approximation techniques, and utilize Markov Chain Monte Carlo methods, demonstrating how to use the Metropolis Hastings algorithm to infer an optimal solution and thus arrive at the centroid graph most descriptive of the entire corpus by construction.\footnote{Source code for this project can be found at https://github.com/ilanashapiro/constraints\_project}

\section{Related work}\label{sec:related_work}
The majority of existing MSA algorithms focus on the contiguous formal segmentation task: boundary detection, followed by section labeling. Segmentation algorithms can be flat or hierarchical, where each level is an increasingly granular contiguous segmentation of the piece. Existing approaches generally utilize matrix factorization, formal grammars, or more recently, neural networks. Oriol Nieto's Music Structure Analysis Framework (MSAF) toolkit \cite{msaf} features most of the state-of-the art matrix factorization approaches, including ordinal linear discriminant analysis \cite{olda}, convex nonnegative matrix factorization \cite{cnmf}, checkerboard \cite{checkerboard}, spectral clustering \cite{scluster}, the Structural Features algorithm \cite{sf}, 2D-Fourier Magnitude Coefficients \cite{2dfmc}, and the Variable Markov Oracle \cite{vmo_segmentation}. These methods use variants of self-similarity matrices (SSMs) for boundary detection, which are symmetric matrices storing pair-wise comparisons between a given set of features. To assign labels, methods such as Gaussian mixture models and nearest neighbor search are employed \cite{msaf}. 

More recently, both supervised \cite{wang_2021} and unsupervised \cite{mccallum_2021, buisson_2022} deep learning approaches to segmentation have studied, as have graph- and grammar-based approaches. Hernandez-Olivan et al. use the graph-based G-PELT algorithm \cite{musicaiz}, while Dai et al. employ a graph-based approach informed by interactions between sections, melody, harmony and rhythm \cite{cmu_dannenberg_2020}. In the grammar realm, Finkensiep et al. attempt a unified model of structure by using a minimal context-free grammar to combine repetition with formal prototypes in a tree-based approach, but they still only operate within the contiguous segmentation domain \cite{repetition_grammars_ismir2023}. 

In the motif extraction domain, algorithms search for disjoint, repeating, and possibly overlapping patterns in a piece. They generally fall into three categories: string-based approaches (e.g. the Variable Markov Oracle \cite{vmo_motifs}), where music data is represented as a one-dimensional pitch sequence and repeated patterns are detected with sub-string matching; geometry-based approaches (e.g. Hsiao et al's BPS-motif discovery algorithm \cite{Hsiao_2023_motifs}), where music data is represented as multidimensional point sets and \textit{translatable subsets} identify repeating patterns; and feature-based (e.g. \cite{features_motifs}) approaches, which learn features from music data, and retrieve patterns with clustering or classification of the features as repeated patterns.
%The Variable Markov Oracle offers a quality string-based approach \cite{vmo_motifs}, although our experiments reveal that it struggles to detect motifs of length $>2$.  

Recent approaches in harmony identification are centered around neural networks, such as using multi-task
learning with recurrent neural networks and long short term memory units to detect functional harmonic relationships in a piece \cite{chen_2018_harmony}, as well as developing transformer models that incorporate chord segmentation into the recognition process \cite{chen_2019_harmony}. Until very recently, Justin Salamon's Melodia algorithm was the state of the art in melody extraction. It comprises sinusoid extraction, salience functions, contour creation, and melody selection, and automatically estimates the fundamental frequency corresponding to the pitch of the predominant melodic line of a piece of polyphonic music. Since then, approaches have shifted to neural networks, such as lightweight deep bidirectional
LSTM models \cite{kosta_22_melody} and transformers \cite{midibert}.

To our knowledge, little work has been done in developing a unified model of structure for either a single piece or across a corpus. The closest we are aware of is Halley Young's \textit{prototype graph}, a bipartite graph that represents musical form as a network of relationships between ``prototype nodes" (specific musical elements) and the music they represent, as well as the music-theoretic relationships between musical spans and their respective nodes \cite{young_2022}. However, the prototype graph does not encode hierarchy, and it is limited to a single piece.


\section{Abstract Representation}\label{sec:representation}


\subsection{Semantic Temporal Graph} \label{subsec:st_graph}
We seek a unified model of musical structure that captures the semantic, music theoretic levels of the compositional hierarchy, as well as the temporal relationships between them. The \textit{semantic temporal graph}, or STG, is a novel data structure serving as a meta-representation of musical structure that unifies these objectives. The STG is $k$-partite directed acyclic graph (DAG). Each of the $k$ layers encodes a level in the semantic hierarchy dictated by music theory. From top to bottom, this hierarchy consists of large scale form, motifs, rhythm, harmony, and finally melodies constituting specific note events \cite{msaf}. Individual levels themselves can form sub-hierarchies of increasing granularity, as is commonly seen with the segmentation algorithms corresponding to large scale form.

In the STG, nodes encode labels from the relevant MSA algorithm, and contain associated time intervals given by the algorithm. At each level, these intervals are converted to indices by ordering their start times. Edges encode temporal relationships between nodes of adjacent levels. Specifically, for node $n$ at level $i$, $n$ must have either one or two parents in level $i-1$: one if its associated time interval is a total subset of its parent's, and two if its time interval begins in one parent's, and ends in the other's.

\subsection{Building the Graph}\label{subsec:build}

In order to visualize the STG more clearly, we must first establish how it is built. In this paper, we build STGs that unify hierarchical formal segmentation and disjoint motif repetition, with plans in the near future to add layers for rhythm, harmony, and melody. In order to parse the results of any MSA algorithm into a format suitable for the STG, we consider the standard MIREX formats they adhere to. 

The structural segmentation task was most recently proposed in the 2017 MIREX competition \cite{MIREX_2017_form}. It defines the following standard output format:
\begin{lstlisting}
<onset_time(sec)>\t<offset_time(sec)>\t<label>\n
<onset_time(sec)>\t<offset_time(sec)>\t<label>\n
...
\end{lstlisting}
where $\backslash$t denotes a tab and $\backslash$n denotes the end of line. The $<$ and $>$ characters are not included. Thus, an example output file could look like:
\begin{lstlisting}
0.000    5.223    A
5.223    15.101   B
15.101   20.334   A
\end{lstlisting}
Hierarchical segmentations will have multiple of these lists separated by a newline.

MIREX 2017 also dictates the standard output format for motif detection algorithms \cite{MIREX_2017_motif}. Ontimes (in seconds) of notes in the pattern are in the left column, and MIDI note numbers are on the right. Each pattern occurrence is given before continuing to the next pattern, and occurrences can be differing lengths. An example output would resemble:
\begin{lstlisting}
pattern1 
occurrence1 
7.00000, 45.00000 
... 
11.00000, 60.00000 
occurrence2 
31.00000, 57.00000 
...
patternM 
occurrence1 
9.00000, 58.00000 
...
occurrencem 
100.00000, 62.00000 
...
\end{lstlisting}

Given these standard MIREX formats, we parse this data into a format suitable for the STG. Each ``chunk" of the data, separated by a newline, forms a level in the STG, and each line in a chunk corresponds to a node. Consider Figure \ref{fig:form_parse}, which demonstrates the parsing process for a segmentation hierarchy with two levels. We start with the MIREX segmentation output in step 1. In step 2, we number each segmentation level (i.e. text chunk) and extract the segment label and time interval from each line. This gives us the preliminary node label \textbf{S}\{segment label\}\textbf{L}\{segment level number\}\textbf{I}\{time interval\}. Finally, in step 3 we convert each time interval into an index corresponding to that line's position in the level, sorted by start time. In the case of segmentation, this matches the MIREX line order. We now have the final segmentation node label \textbf{S}\{segment label\}\textbf{L}\{segment level number\}\textbf{N}\{label index within level\}. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{figs/form_parse}
  \caption{Parsing Formal Segmentation}
  \label{fig:form_parse}
\end{figure}

We repeat this process for motifs as in Figure \ref{fig:motif_parse}. Motif analyses are single level, i.e. they do not output sub-hierarchies like segmentation often does. Consider the MIREX motif output in step 1. Each pattern/motif occurrence's time interval is defined as the ontime of its first note to the ontime of its last. We extract pattern and occurrence numbers in step 2 to arrive at the preliminary node label \textbf{P}\{pattern number\}\textbf{O}\{occurrence number\}\textbf{I}\{time interval\}. We then order the preliminary labels by start time, as unlike in segmentation, pattern occurrences are not ordered temporally in MIREX format. We then assign indices to this ordering to arrive at the final motif node label \textbf{P}\{pattern number\}\textbf{O}\{occurrence number\}\textbf{N}\{chronologic occurrence index\}. This is reflected in step 3, where occurrence 2 of pattern 1 is assigned index 3 instead of 2. 
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{figs/motif_parse}
  \caption{Parsing Motifs}
  \label{fig:motif_parse}
\end{figure}

In all cases, the time interval is stored as node metadata, and determines what that node's parent(s) will be.

\subsection{STG Examples}\label{subsec:stg_ex}

In the following examples, we use hierarchical spectral clustering from the MSAF toolkit for segmentation \cite{msaf, scluster}, and Hsiao et al's BPS-motif discovery algorithm for motifs \cite{Hsiao_2023_motifs}. To better visualize the STG's structure, first consider the following subgraph taken from an STG generated for the first movement exposition of the piano transcription of Beethoven's Symphony No. 1, Op. 21 in Figure \ref{fig:stg_ex}.\footnote{MIDI file is from the LOP database, which can be found here: https://qsdfo.github.io/LOP/database} The nodes are taken from levels 4 and 5 of the segmentation sub-hierarchy.
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\linewidth]{figs/stg_example}
  \caption{STG Subgraph Example}
  \label{fig:stg_ex}
\end{figure}
Node S3L5N2’s time interval is a total subset of S1L4N2's, while S0L5N1’s time interval starts in S0L4N1’s, but ends in S2L4N2’s. The entire STG generated for this piece, unifying hierarchical formal segmentation with disjoint motif detection, is shown in Figure \ref{fig:stg_full}. The segmentation nodes are easily visible, and the motif nodes form the crowded bottom layer.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{figs/stg_full}
  \caption{STG Subgraph Example}
  \label{fig:stg_full}
\end{figure}
\vspace{-6mm}
\section{Synthesis}\label{sec:synthesis}
\subsection{Distance Metric}\label{subsec:dist_metric}
In order to derive a representative "centroid" STG from a corpus of STGs, we must first define a distance metric between them. The distance between two STGs $G_1$ and $G_2$ is quantified by the \textit{graph edit distance} (GED) between them, i.e. the minimum number of graph operations necessary to transform $G_1$ into $G_2$. We define six valid graph operations: node and edge deletion, insertion, and substitution. 

Calculating exact graph edit distance is an NP-hard problem, and thus intractable for graphs of these sizes. Fortunately, the Python package networkX offers a highly customizable approximation algorithm \verb!optimize_edit_paths!\footnote{https://networkx.org/documentation/stable/reference/algorithms/ generated/networkx.algorithms.similarity.optimize\_edit\_paths.html} that efficiently computes the approximate GED and also returns the associated sequence of transforms in the edit path. 

\subsection{Stochastic Optimization}\label{subsec:stoch_opt}
Consider the set $G$ of STGs. With the GED given by \verb!optimize_edit_paths! as our cost function $c$, we seek the centroid STG $g*$ that minimizes $c$ over $G$. This is an NP-hard constraint satisfaction problem. Due to the graph sizes, the problem is intractable with deterministic SMT solvers like Z3. If we represent this an integer linear programming (ILP) problem, the size of each encoded graph would still blow up even the most efficient ILP solver. Thus, we turn to stochastic optimization. 

Although this is still a work in progress, we introduce a framework for finding $g*$ using a Markov Chain Monte Carlo (MCMC) sampler. MCMC methods sample from an arbitrary probability distribution $p$. The equation for $p$ is known, but it is unknown how to generate a random number from $p$. The idea behind MCMC is to define a Markov chain over possible $x$ values, denoted $\{x^{(0)}, x^{(1)}, \ldots, x^{(N)}\}$ such that as $n \to \infty$, $x_n \sim p(x)$. 

The Metropolis Hastings algorithm is a popular MCMC algorithm that we adapt for the centroid graph problem. Its psuedocode is shown in Algorithm \ref{alg:metropolis_hastings}.

\begin{algorithm}
\caption{Metropolis-Hastings Algorithm}\label{alg:metropolis_hastings}
\begin{algorithmic}[1] % The number tells where the line numbering should start
\Procedure{MetropolisHastings}{$p, q, x_0, N$}
    \State Initialize $x^{(0)} = x_0$
    \For{$i = 0$ to $N-1$}
        \State Propose $t \sim q(x'|x^{(i)})$
        \State Apply $t$ to $x^{(i)}$ to obtain rewrite $x'$
        \State Calculate acceptance ratio \Statex $\qquad\qquad\alpha = \min\left(1, \frac{p(x')q(x^{(i)}|x')}{p(x^{(i)})q(x'|x^{(i)})}\right)$
        \State Draw $u \sim \text{Uniform}(0, 1)$
        \If{$u < \alpha$}
            \State Accept the proposal: $x^{(i+1)} = x'$
        \Else
            \State Reject the proposal: $x^{(i+1)} = x^{(i)}$
        \EndIf
    \EndFor
    \State \textbf{return} $\{x^{(0)}, x^{(1)}, \ldots, x^{(N)}\}$
\EndProcedure
\end{algorithmic}
\label{alg:metropolis_hastings}
\end{algorithm}

In more detail, given a probability distribution $p$ we want to sample from, suppose that the current state of the Markov chain (i.e. the current rewrite/centroid graph) is $x^{(i)}$, and we want to generate $x^{(i+1)}$. We first generate proposal $t$ from the proposal distribution $q$, which we know how to sample from. We apply $t$ to $x^{(i)}$ to obtain the new rewrite, or updated centroid graph, $x'$. Then, we execute the accept-reject step by computing the acceptance probability $\alpha$ (line 5 of Algorithm \ref{alg:metropolis_hastings}). Consider the ratio $\frac{q(x^{(i)}|x')}{q(x'|x^{(i)})}$ that appears in the $\alpha$ equation. $q(x'|x^{(i)})$ describes the probability that proposal $t$ is chosen given the current state $x^{(i)}$. $q(x^{(i)}|x')$, however, is the probability that this proposal is $undone$, i.e. the probability that we choose the inverse of $t$ to return from the new rewrite $x'$ to the current rewrite $x^{(i)}$. If the proposal distribution is symmetric, these probabilities are equal. We accept the rewrite $x'$ if the uniformly generated $u$ falls in $\alpha$, setting $x^{(i+1)} = x'$, and reject otherwise. In the limit, we are guaranteed to arrive at the optimal rewrite $x^{(N)}$ \cite{metropolis_hastings}.

We adapt this algorithm to find the centroid graph. Our target distribution $p$ is derived from the discrete cost function $c$, which recall is the label-aware GED given by \verb!optimize_edit_paths!. In order to convert this into a continuous probability distribution, we use the technique suggested by Schkufza et al. \cite{cacm} in Equation \ref{eqn:c_to_p}.
\begin{equation}
p(x')=\frac{1}{Z}\exp(-\beta\cdot c(x'))
\label{eqn:c_to_p}
\end{equation}
where $\beta$ is the temperature parameter, and $Z$ is the normalizing constant. Computing $Z$ is normally intractable, but since we take the ratio of $p$ in $\alpha$, this becomes unnecessary as the $Z$'s cancel out. We define our $c(x')$ in Equation \ref{eqn:cost}.
\begin{equation}
c(x') = \sum_g^G \verb!optimize_edit_paths!(x', g)
\label{eqn:cost}
\end{equation}
In other words, $c(x')$ is the sum of the GED between itself and each STG $g$ in the corpus.

We now consider the proposal distribution $q$, where we sample a potential transform $t$ that will be applied to the current rewrite (i.e. centroid graph) $x^{(i)}$. An example $t$ would be ``add node S0L7N4". In order to strategically define the space of possible transforms, we consider the other value \verb!optimize_edit_paths! returns: the sequence of transforms constituting the edit path. Consider Figure \ref{fig:proposal_dist}. 
 \begin{figure}[h!]
  \centering
  \includegraphics[width=0.4\linewidth]{figs/proposal_dist}
  \caption{Transform Paths from $x^{(i)}$}
  \label{fig:proposal_dist}
\end{figure}
Each edit path $s_j$ from $x^{(i)}$ to a graph $G_j$ in the corpus consists of a sequence of transforms $(t_{j_1}, t_{j_1}, \ldots, t_{j_m})$ that changes $x^{(i)}$ into $G_j$. 

We collect all $t$ values from the intersection of $s_1, s_2, \ldots, s_n$ to form the set $T$, which represents the space of transforms, or proposals, that we will sample from. In order to prioritize more likely transforms, we compute the count of each transform in $T$, and assign its count as its weight value. This results in the asymmetric proposal distribution $q$. It is likely that many transforms will not have inverses in $T$, since $T$ only includes the transforms that occur in the edit paths. We solve this by manually adding the nonexistent transform inverses with counts of zero, and then perform additive smoothing to give them very small nonzero probabilities for the sake of computing $\alpha$. Our $q$ is also $adaptive$, meaning it changes at each iteration. 

There are some problems with this approach.  We are still unsure whether the adaptive proposal distribution $q$ undermines the Markov property of the chain, and therefore convergence of the algorithm. Furthermore, all MCMC algorithms are guaranteed convergence in the infinite limit, but we are unsure how to determine when the algorithm sufficiently converges in practice. The former could be solved by discarding the custom (although theoretically more efficient) proposal distribution to make it symmetric and constant, but the latter remains unclear. Furthermore, there are two levels of approximation occurring here: one at the level of the GED itself, and another at the level of the MCMC process. This introduces a potentially unacceptable level of approximation in the result. For these reasons, we may shift our approach to other optimization strategies, such as a custom greedy edit distance algorithm. 
 
%\section{Evaluation} \label{subsec:eval}

\section{Conclusions and Future Work}
In this paper we have presented the semantic temporal graph, a unified meta-representation of complete musical structure that encapsulates the both the intrinsic compositional hierarchy and the temporal relationships between elements of adjacent levels. Such a model is essential to comprehending the fusion of the fundamental components that constitute the piece's core architecture, something cannot be done by considering each level in isolation. The STG thus is a vital contribution to the holistic cognition and analysis of musical form. 

Furthermore, we have introduced a novel approach rooted in stochastic optimization for deriving an STG representative of a dataset of music. By defining the GED between two STGs as a cost function to minimize over the corpus, we are able to describe an application of the Metropolis Hastings algorithm allowing us to construct the ``centroid" STG for the corpus that minimizes this cost by construction. To our knowledge, this is the inaugural presentation of a method for discerning the overarching structure of an entire dataset, rather than just individual pieces.

However, due to the uncertainties we have regarding the convergence and magnitude of approximation of the algorithm, we intend branch out and explore a custom edit distance algorithm that builds the centroid greedily. We also will add the remaining layers of the compositional hierarchy to the STG; namely, rhythmic contour, functional harmonic contour, and melodic contour, and derive the centroid using these more robust STGs. In addition, we plan to conduct a qualitative evaluation of the STG as a concept, as well as a quantitative evaluation of the centroid STG. 


Finally, in future research we plan to use the STG as a system of constraints to induce structure in generative models, particularly transformers. Such models suffer from what is known as the \textit{long sequence problem}, in that they cannot handle very long sequences as input since their self-attention operations exhibit quadratic time and space complexity \cite{mao2024iceformer}. This results in a lack of global relational cohesion in their outputs. By using the STG as a system of unified musical constraints, we will explore how to $limit$, rather than condition, the model to adhere to this structure. Similar work has been done by Young et al. \cite{young_2022}, Wang et al. \cite{wang2024wholesong}, and Dai et al. \cite{musicframeworks}, though no one has ever attempted to limit, rather than condition, a model to a complete hierarchy of music theoretic constraints. 


%\section{Acknowledgments}
%\textbf{Do not include in your submission, only in your camera ready version}. This section can be used to refer to any individuals or organizations that should be acknowledged in this paper. This section does \textit{not} count towards the page limit for scientific content.



\bibliography{ISMIRtemplate}

% For non bibtex users:
%\begin{thebibliography}{citations}
% \bibitem{Author:17}
% E.~Author and B.~Authour, ``The title of the conference paper,'' in {\em Proc.
% of the Int. Society for Music Information Retrieval Conf.}, (Suzhou, China),
% pp.~111--117, 2017.
%
% \bibitem{Someone:10}
% A.~Someone, B.~Someone, and C.~Someone, ``The title of the journal paper,''
%  {\em Journal of New Music Research}, vol.~A, pp.~111--222, September 2010.
%
% \bibitem{Person:20}
% O.~Person, {\em Title of the Book}.
% \newblock Montr\'{e}al, Canada: McGill-Queen's University Press, 2021.
%
% \bibitem{Person:09}
% F.~Person and S.~Person, ``Title of a chapter this book,'' in {\em A Book
% Containing Delightful Chapters} (A.~G. Editor, ed.), pp.~58--102, Tokyo,
% Japan: The Publisher, 2009.
%
%
%\end{thebibliography}

\end{document}

